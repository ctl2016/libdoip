# yolov5s

import cv2
import torch
import os
from PIL import Image

# Model
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', trust_repo=True, pretrained=True) # force_reload=False, 

# Images
#for f in 'zidane.jpg', 'bus.jpg':
#    torch.hub.download_url_to_file('https://ultralytics.com/images/' + f, f)  # download 2 images
im1 = Image.open('R-C.jfif')  # PIL image
#im2 = cv2.imread('bus.jpg')[..., ::-1]  # OpenCV image (BGR to RGB)

# Inference
#results = model([im1, im2], size=640)  # batch of images
results = model([im1], size=640)  # batch of images

print(type(results))

# Results
results.print()
#results.save()  # or .show()
results.show()
results.xyxy[0]  # im1 predictions (tensor)
results.pandas().xyxy[0]  # im1 predictions (pandas)
#      xmin    ymin    xmax   ymax  confidence  class    name
# 0  749.50   43.50  1148.0  704.5    0.874023      0  person
# 1  433.50  433.50   517.5  714.5    0.687988     27     tie
# 2  114.75  195.75  1095.0  708.0    0.624512      0  person
# 3  986.00  304.00  1028.0  420.0    0.286865     27     tie


#ssd

import torch
import torchvision
from torchvision import transforms
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image

# 加载预训练的 SSD 模型
model = torchvision.models.detection.ssdlite320_mobilenet_v3_large(weights=True)

# 设置模型为评估模式
model.eval()

# 定义转换
transform = transforms.Compose([
    transforms.ToTensor(),
])

# 加载图像并进行预处理
image = Image.open("R-C.jfif")
image_tensor = transform(image)
image_tensor = image_tensor.unsqueeze(0)  # 添加一个维度作为 batch

# 使用模型进行预测
with torch.no_grad():
    predictions = model(image_tensor)

# 可视化预测结果
fig, ax = plt.subplots(1)
ax.imshow(image)

# 处理预测结果
# 假设 predictions 包含了预测的框、类别和置信度信息
# 这里只是一个示例，实际情况下需要根据具体的输出格式来处理预测结果
boxes = predictions[0]['boxes']
labels = predictions[0]['labels']
scores = predictions[0]['scores']

coco_names_url = "data/coco-labels-2014_2017.txt"

# 从URL中获取类别名称
with open(coco_names_url, 'r') as f:
    coco_names = [line.strip() for line in f]

for i in range(len(boxes)):
    if scores[i] < 0.2:
        continue
    box = boxes[i]
    label = labels[i]
    # 绘制预测框
    rect = patches.Rectangle((box[0], box[1]), box[2] - box[0], box[3] - box[1], linewidth=1, edgecolor='r', facecolor='none')
    ax.add_patch(rect)
    # 添加类别标签
    ax.text(box[0], box[1], f'{coco_names[label]}', fontsize=8, color='r')

plt.show()



# maskrcnn

import torch
import torchvision.transforms as T
from torchvision.models.detection import maskrcnn_resnet50_fpn
from torchvision import datasets
from PIL import Image
import matplotlib.pyplot as plt
from collections import defaultdict

import json
from urllib.request import urlopen

# COCO 数据集的类别名称的 URL
coco_names_url = "data/coco-labels-2014_2017.txt"

# 从URL中获取类别名称
with open(coco_names_url, 'r') as f:
    coco_names = [line.strip() for line in f]
    
# 加载预训练的 Mask R-CNN 模型
model = maskrcnn_resnet50_fpn(pretrained=True)
model.eval()

# 准备输入图像
image_path = 'p.webp'  # 替换为你的图像路径
input_image = Image.open(image_path)
# 对图像进行预处理
transform = T.Compose([T.ToTensor()])
input_tensor = transform(input_image)

# 执行推理
with torch.no_grad():
    prediction = model([input_tensor])

# 获取预测的类别标签
predicted_classes = prediction[0]['labels']
predicted_labels = defaultdict(int)

for lab in predicted_classes:
    if lab > len(coco_names):
        print(f'lab:{lab}')
        break
    l = "{:<3}: {}".format(lab.item(), coco_names[lab.item()])
    if l not in predicted_labels:
        predicted_labels[l] = 1
    else:
        predicted_labels[l] += 1

for label, name in predicted_labels.items():
    print(f"{label:<3}: {name}")
    
# 可视化预测结果
plt.imshow(input_image)
ax = plt.gca()
for element, label in zip(prediction[0]['boxes'], predicted_classes):
    if label == label:
        xmin, ymin, xmax, ymax = element
        rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, edgecolor='red', linewidth=1)
        ax.add_patch(rect)
        class_name = coco_names[label]
        ax.text(xmin, ymin, f'{class_name}', fontsize=10, color='red')  # 显示类别标签
plt.show()

print('prediction ok')


# load onnx

import onnx
import onnxruntime
import numpy as np
import torch
from PIL import Image, ImageOps
import torchvision.transforms as transforms
import matplotlib.pyplot as plt

# 加载ONNX文件
onnx_model = onnx.load("last.onnx")

# 将ONNX文件转化为ORT格式
ort_session = onnxruntime.InferenceSession("best.onnx")

input_shape = ort_session.get_inputs()[0].shape
print("Expected input shape:", input_shape)

# 输入数据
#input_data = np.random.random(size=(1, 3, 32, 32)).astype(np.float32)
input_img = Image.open('2.png')

# 可选：将图像转换为灰度图像
input_img = input_img.convert('L')

# 定义转换
preprocess = transforms.Compose([
    transforms.Resize((32, 32)),  # 调整大小为模型期望的输入尺寸
    transforms.ToTensor(),  # 将图像转换为张量
    #transforms.Normalize((0.5,), (0.5,))
])

# 应用转换
input_data = preprocess(input_img)
input_data = input_data.unsqueeze(0)  # 添加 batch 维度
print(input_data.shape)
input_data = input_data.expand(-1, 3, -1, -1)
#input_data = torch.cat((input_data, input_data, input_data), dim=1)

print(input_data.shape)

# 将数据转换为 numpy 数组
input_data_np = input_data.numpy()

# 运行模型
input_name = ort_session.get_inputs()[0].name
output_name = ort_session.get_outputs()[0].name
outputs = ort_session.run([output_name], {input_name: input_data_np})

# 输出结果
print(outputs)

_, predicted = torch.max(torch.tensor(outputs[0]), 1)
print("Predicted class:", predicted.item())

input_data_np = input_data.squeeze().numpy()
print(input_data_np.shape)
img = np.transpose(input_data_np, (1, 2, 0))  # 调整通道顺序
print(img.shape)
plt.imshow(img)
plt.show()
